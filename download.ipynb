{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250a8ca3-882a-408a-8b13-8643730d0d66",
   "metadata": {},
   "source": [
    "# Download\n",
    "\n",
    "Fetch, save and combine food inspection records [from Open Minneapolis](https://opendata.minneapolismn.gov/datasets/4eea8bf452e34f8c9d9ac07c54c0b4ab_0/about)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577e21e-47f2-4a6f-af6c-eeefb91fc0b0",
   "metadata": {},
   "source": [
    "Import Python tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16bc5fd6-2898-47a0-ab6d-82ccdff7cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e1dab-9320-4868-b499-01ea1f50d2d5",
   "metadata": {},
   "source": [
    "Put together a function that can fetch all of the records in the given year. This is necessary because of the 32,000 record count limit in the Open Minneapolis API. I'm betting that we'll never top that number if we segment by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2149575-cbd4-411d-9825-3d63a8f44ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(year: int) -> Any:\n",
    "    # Set the URL\n",
    "    url = \"https://services.arcgis.com/afSMGVsC7QlRK1kZ/arcgis/rest/services/Food_Inspections/FeatureServer/0/query\"\n",
    "\n",
    "    # Make our request\n",
    "    r = requests.get(\n",
    "        url,\n",
    "        params={\n",
    "            # Set a date filter with the input year\n",
    "            \"where\": f\"DateOfInspection>'{year}-01-01' AND DateOfInspection < '{year}-12-31'\",\n",
    "            # The GeoJSON stuff\n",
    "            \"f\": \"geojson\",\n",
    "            \"outSR\": \"4326\",\n",
    "            # Take all the fields\n",
    "            \"outFields\": \"*\"\n",
    "        }\n",
    "    )\n",
    "    # Make sure the response is okay\n",
    "    assert r.ok\n",
    "    # Get the data as JSON\n",
    "    data = r.json()\n",
    "    # Print the result\n",
    "    print(f\"{year}: {len(data['features'])} records\")\n",
    "    # Make sure we don't have exactly 32,000 records, which is a telltale sign we've topped out\n",
    "    assert len(data['features']) != 32_000\n",
    "    # Return the result\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6878f38a-e613-4051-b43f-6a26ed957acc",
   "metadata": {},
   "source": [
    "Go get every year up until the current day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "288f9586-e8f3-4200-9a1b-1b0d482a456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = list(range(2021, datetime.now().year + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82330a00-e403-49be-9206-8f3137dd899f",
   "metadata": {},
   "source": [
    "Loop through the years and write out all the responses as year stamped files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c72d6b0-48e5-477f-98d5-e86a3ed9799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021: 7748 records\n",
      "2022: 10609 records\n",
      "2023: 13835 records\n",
      "2024: 7084 records\n"
     ]
    }
   ],
   "source": [
    "for year in year_list:\n",
    "    geojson = get_year(year)\n",
    "    with open(f\"{year}.geojson\", \"w\") as fp:\n",
    "        json.dump(geojson, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d88269c-dd79-4f3c-b3b5-f1dde63614da",
   "metadata": {},
   "source": [
    "Combine all of the files into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52e97d2b-4197-496e-9c3f-a537da13a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_list = []\n",
    "for year in year_list:\n",
    "    gdf = gpd.read_file(f\"{year}.geojson\")\n",
    "    gdf_list.append(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "894be5f4-244c-4e69-aaff-fcfc874a923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(gdf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58f4d8-822b-44bb-ba8b-2e033508580d",
   "metadata": {},
   "source": [
    "Convert it into a GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c5489a6-af61-4b0e-bba9-00547af4aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eac46b-29d3-414a-aa83-7a85518427cf",
   "metadata": {},
   "source": [
    "Write the result out to a combined file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16b2b4ab-d385-48bd-8070-c1155eab4efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\"food-inspections.geojson\", driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
